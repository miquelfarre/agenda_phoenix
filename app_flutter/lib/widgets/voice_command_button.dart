import 'package:flutter/material.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import '../services/ai/gemini_voice_service.dart';
import '../services/ai/ai_config_service.dart';
import '../services/ai/voice_conversation_context.dart';
import '../screens/voice_command_confirmation_screen.dart';
import '../screens/voice_conversation_screen.dart';
import '../config/debug_config.dart';
import 'voice_recording_dialog.dart';

/// Provider para el servicio de voz de Gemini
final geminiVoiceServiceProvider = FutureProvider<GeminiVoiceService?>((ref) async {
  print('üîÑ ===== INICIALIZANDO PROVIDER DE VOZ =====');
  DebugConfig.info('üîÑ ===== INICIALIZANDO PROVIDER DE VOZ =====', tag: 'VoiceButton');
  try {
    print('üìã Obteniendo AIConfigService...');
    DebugConfig.info('üìã Obteniendo AIConfigService...', tag: 'VoiceButton');
    final config = await AIConfigService.getInstance();

    print('üîç Verificando API key y configuraci√≥n...');
    print('   - hasApiKey: ${config.hasApiKey}');
    print('   - voiceCommandsEnabled: ${config.voiceCommandsEnabled}');
    DebugConfig.info('üîç Verificando API key y configuraci√≥n...', tag: 'VoiceButton');
    DebugConfig.info('   - hasApiKey: ${config.hasApiKey}', tag: 'VoiceButton');
    DebugConfig.info('   - voiceCommandsEnabled: ${config.voiceCommandsEnabled}', tag: 'VoiceButton');

    if (!config.hasApiKey || !config.voiceCommandsEnabled) {
      print('‚ö†Ô∏è Gemini API no configurada o deshabilitada');
      DebugConfig.info('‚ö†Ô∏è Gemini API no configurada o deshabilitada', tag: 'VoiceButton');
      return null;
    }

    final apiKey = config.geminiApiKey!;
    print('‚úÖ API key disponible (${apiKey.length} chars), creando GeminiVoiceService...');
    DebugConfig.info('‚úÖ API key disponible, creando GeminiVoiceService...', tag: 'VoiceButton');
    return GeminiVoiceService(geminiApiKey: apiKey);
  } catch (e) {
    print('‚ùå Error al inicializar GeminiVoiceService: $e');
    DebugConfig.error('‚ùå Error al inicializar GeminiVoiceService: $e', tag: 'VoiceButton');
    return null;
  }
});

/// Bot√≥n flotante para activar comandos de voz
class VoiceCommandButton extends ConsumerStatefulWidget {
  /// Callback cuando se ejecuta exitosamente un comando
  final Function(dynamic result)? onCommandExecuted;

  /// Color del bot√≥n
  final Color? backgroundColor;

  /// Icono del bot√≥n
  final IconData? icon;

  const VoiceCommandButton({
    super.key,
    this.onCommandExecuted,
    this.backgroundColor,
    this.icon,
  });

  @override
  ConsumerState<VoiceCommandButton> createState() => _VoiceCommandButtonState();
}

class _VoiceCommandButtonState extends ConsumerState<VoiceCommandButton>
    with SingleTickerProviderStateMixin {
  bool _isRecording = false;
  bool _isProcessing = false;
  late AnimationController _pulseController;

  @override
  void initState() {
    super.initState();
    _pulseController = AnimationController(
      vsync: this,
      duration: const Duration(milliseconds: 1000),
    )..repeat(reverse: true);
  }

  @override
  void dispose() {
    _pulseController.dispose();
    super.dispose();
  }

  Future<void> _handleVoiceCommand() async {
    print('üé§ ===== BOT√ìN DE VOZ PRESIONADO ===== ${DateTime.now()}');
    DebugConfig.info('üé§ ===== BOT√ìN DE VOZ PRESIONADO =====', tag: 'VoiceButton');

    // Mostrar un di√°logo visual para confirmar que el bot√≥n funciona
    if (mounted) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(
          content: Text('üé§ Bot√≥n presionado - Iniciando...'),
          duration: Duration(seconds: 2),
        ),
      );
    }

    final voiceServiceAsync = ref.read(geminiVoiceServiceProvider);

    final voiceService = voiceServiceAsync.when(
      data: (service) {
        print('‚úÖ Servicio de voz disponible: ${service != null}');
        DebugConfig.info('‚úÖ Servicio de voz disponible', tag: 'VoiceButton');
        return service;
      },
      loading: () {
        print('‚è≥ Servicio de voz cargando...');
        DebugConfig.info('‚è≥ Servicio de voz cargando...', tag: 'VoiceButton');
        return null;
      },
      error: (error, stack) {
        print('‚ùå Error en servicio de voz: $error');
        DebugConfig.error('‚ùå Error en servicio de voz: $error', tag: 'VoiceButton');
        return null;
      },
    );

    if (voiceService == null) {
      print('‚ùå Servicio de voz es NULL');
      DebugConfig.error('‚ùå Servicio de voz no disponible', tag: 'VoiceButton');
      _showError('Gemini API key no configurada. '
                'Ve a Configuraci√≥n para a√±adir tu API key.');
      return;
    }

    try {
      print('üî¥ Iniciando grabaci√≥n...');
      DebugConfig.info('üî¥ Iniciando grabaci√≥n...', tag: 'VoiceButton');
      setState(() => _isRecording = true);

      // 1. Grabar audio y transcribir
      print('üéôÔ∏è Llamando a processVoiceCommand()...');
      DebugConfig.info('üéôÔ∏è Llamando a processVoiceCommand()...', tag: 'VoiceButton');
      final result = await voiceService.processVoiceCommand();
      print('üì• Resultado recibido!');

      DebugConfig.info('üì• Resultado recibido: success=${result.success}, needsConfirmation=${result.needsConfirmation}', tag: 'VoiceButton');
      DebugConfig.info('üìù Texto transcrito: "${result.transcribedText}"', tag: 'VoiceButton');

      setState(() => _isRecording = false);

      if (!result.success) {
        print('‚ùå result.success = false');
        DebugConfig.info('‚ö†Ô∏è Comando no exitoso', tag: 'VoiceButton');
        DebugConfig.error('‚ùå Error: ${result.message}', tag: 'VoiceButton');
        _showError(result.message ?? 'Error al procesar comando');
        return;
      }

      print('‚úÖ result.success = true, continuando...');
      print('üîç DEBUG: result.interpretation = ${result.interpretation}');
      print('üîç DEBUG: result.transcribedText = ${result.transcribedText}');

      // 2. Verificar si tenemos interpretaci√≥n
      if (result.interpretation == null) {
        print('‚ùå result.interpretation es NULL');
        DebugConfig.info('‚ö†Ô∏è No hay interpretaci√≥n para mostrar', tag: 'VoiceButton');
        _showError('No se pudo interpretar el comando');
        return;
      }

      print('‚úÖ Tenemos interpretaci√≥n, extrayendo datos...');

      // 3. Verificar si faltan campos obligatorios
      final action = result.interpretation!['action'] as String;
      print('üîç DEBUG: action extra√≠da = $action');

      final parameters = result.interpretation!['parameters'] as Map<String, dynamic>;
      print('üîç DEBUG: parameters extra√≠dos = $parameters');
      print('üîç DEBUG: parameters.isEmpty = ${parameters.isEmpty}');

      final missingFields = RequiredFields.findMissing(action, parameters);

      print('üìä Acci√≥n: $action');
      print('üìä Par√°metros actuales: $parameters');
      print('üìä Campos faltantes: $missingFields');
      print('üìä missingFields.isNotEmpty: ${missingFields.isNotEmpty}');
      print('üìä missingFields.length: ${missingFields.length}');

      if (missingFields.isNotEmpty) {
        // Faltan campos obligatorios ‚Üí Iniciar di√°logo conversacional
        print('üó£Ô∏è Faltan campos obligatorios, iniciando di√°logo conversacional...');
        DebugConfig.info('üó£Ô∏è Iniciando di√°logo conversacional para recolectar: $missingFields', tag: 'VoiceButton');

        await _startConversationalDialog(
          voiceService,
          result.transcribedText!,
          action,
          parameters,
          missingFields,
        );
      } else {
        // Todos los campos est√°n completos ‚Üí Ir a confirmaci√≥n final
        print('‚úÖ Todos los campos completos, mostrando confirmaci√≥n final');
        DebugConfig.info('‚úÖ Mostrando pantalla de confirmaci√≥n', tag: 'VoiceButton');

        await _showConfirmationScreen(
          voiceService,
          result.transcribedText!,
          result.interpretation!,
        );
      }

    } catch (e, stackTrace) {
      DebugConfig.error('‚ùå ERROR CR√çTICO en comando de voz: $e', tag: 'VoiceButton');
      DebugConfig.error('Stack trace: $stackTrace', tag: 'VoiceButton');
      setState(() {
        _isRecording = false;
        _isProcessing = false;
      });
      _showError('Error: ${e.toString()}');
    }
  }

  /// Inicia la pantalla conversacional para recolectar datos faltantes
  Future<void> _startConversationalDialog(
    GeminiVoiceService voiceService,
    String originalCommand,
    String action,
    Map<String, dynamic> collectedParameters,
    List<String> missingFields,
  ) async {
    if (!mounted) return;

    print('üó£Ô∏è Iniciando di√°logo conversacional');
    print('   - Comando original: "$originalCommand"');
    print('   - Acci√≥n: $action');
    print('   - Par√°metros ya recolectados: $collectedParameters');
    print('   - Campos faltantes: $missingFields');

    // Crear contexto inicial
    var conversationContext = VoiceConversationContext(
      originalCommand: originalCommand,
      action: action,
      collectedParameters: collectedParameters,
      history: [],
      missingFields: missingFields,
    );

    // Abrir la pantalla conversacional
    final completedContext = await Navigator.of(context).push<VoiceConversationContext>(
      MaterialPageRoute(
        builder: (ctx) => VoiceConversationScreen(
          context: conversationContext,
          voiceService: voiceService,
          onContextUpdated: (updatedContext) {
            conversationContext = updatedContext;
          },
        ),
      ),
    );

    // Si el usuario complet√≥ el di√°logo, mostrar confirmaci√≥n final
    if (completedContext != null && mounted) {
      print('‚úÖ Di√°logo conversacional completado');
      print('   - Par√°metros finales: ${completedContext.collectedParameters}');

      // Crear interpretaci√≥n completa para la pantalla de confirmaci√≥n
      final finalInterpretation = {
        'action': completedContext.action,
        'parameters': completedContext.collectedParameters,
        'confidence': 0.95, // Alta confianza porque el usuario lo complet√≥ manualmente
        'user_confirmation_needed': false,
      };

      await _showConfirmationScreen(
        voiceService,
        completedContext.originalCommand,
        finalInterpretation,
      );
    } else {
      print('‚ö†Ô∏è Di√°logo conversacional cancelado por el usuario');
    }
  }

  Future<void> _showConfirmationScreen(
    GeminiVoiceService voiceService,
    String transcribedText,
    Map<String, dynamic> interpretation,
  ) async {
    if (!mounted) return;

    final result = await Navigator.of(context).push(
      MaterialPageRoute(
        builder: (context) => VoiceCommandConfirmationScreen(
          transcribedText: transcribedText,
          interpretation: interpretation,
          voiceService: voiceService,
        ),
      ),
    );

    if (result != null && widget.onCommandExecuted != null) {
      widget.onCommandExecuted!(result);
    }
  }

  void _showError(String message) {
    if (!mounted) return;

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Row(
          children: [
            const Icon(Icons.error, color: Colors.white),
            const SizedBox(width: 12),
            Expanded(child: Text(message)),
          ],
        ),
        backgroundColor: Colors.red,
        duration: const Duration(seconds: 4),
        action: SnackBarAction(
          label: 'Cerrar',
          textColor: Colors.white,
          onPressed: () {},
        ),
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    final voiceServiceAsync = ref.watch(geminiVoiceServiceProvider);

    final isDisabled = voiceServiceAsync.when(
      data: (service) => service == null,
      loading: () => true,
      error: (_, __) => true,
    );

    return FloatingActionButton.extended(
      onPressed: _isRecording || _isProcessing
          ? null
          : _handleVoiceCommand,
      backgroundColor: _isRecording
          ? Colors.red
          : isDisabled
              ? Colors.grey
              : (widget.backgroundColor ?? Theme.of(context).primaryColor),
      icon: _buildIcon(),
      label: Text(_getButtonText()),
      heroTag: 'voice_command_button',
    );
  }

  Widget _buildIcon() {
    if (_isProcessing) {
      return const SizedBox(
        width: 20,
        height: 20,
        child: CircularProgressIndicator(
          strokeWidth: 2,
          valueColor: AlwaysStoppedAnimation<Color>(Colors.white),
        ),
      );
    }

    if (_isRecording) {
      return AnimatedBuilder(
        animation: _pulseController,
        builder: (context, child) {
          return Transform.scale(
            scale: 1.0 + (_pulseController.value * 0.3),
            child: Icon(
              widget.icon ?? Icons.mic,
              color: Colors.white,
            ),
          );
        },
      );
    }

    return Icon(
      widget.icon ?? Icons.mic,
      color: Colors.white,
    );
  }

  String _getButtonText() {
    if (_isProcessing) {
      return 'Procesando...';
    } else if (_isRecording) {
      return 'HABLA AHORA... (para en 3s de silencio)';
    } else {
      return 'Comando de Voz';
    }
  }
}

/// Versi√≥n simple del bot√≥n como FAB circular
class VoiceCommandFab extends ConsumerStatefulWidget {
  final Function(dynamic result)? onCommandExecuted;
  final Color? backgroundColor;

  const VoiceCommandFab({
    super.key,
    this.onCommandExecuted,
    this.backgroundColor,
  });

  @override
  ConsumerState<VoiceCommandFab> createState() => _VoiceCommandFabState();
}

class _VoiceCommandFabState extends ConsumerState<VoiceCommandFab>
    with SingleTickerProviderStateMixin {
  bool _isRecording = false;
  late AnimationController _pulseController;

  @override
  void initState() {
    super.initState();
    _pulseController = AnimationController(
      vsync: this,
      duration: const Duration(milliseconds: 800),
    )..repeat(reverse: true);
  }

  @override
  void dispose() {
    _pulseController.dispose();
    super.dispose();
  }

  Future<void> _handleVoiceCommand() async {
    print('üé§ ===== VoiceCommandFab PRESIONADO ===== ${DateTime.now()}');

    final voiceServiceAsync = ref.read(geminiVoiceServiceProvider);

    final voiceService = voiceServiceAsync.when(
      data: (service) => service,
      loading: () => null,
      error: (_, __) => null,
    );

    if (voiceService == null) {
      _showError('Gemini API key no configurada. Ve a Configuraci√≥n ‚Üí Configurar IA para a√±adir tu API key.');
      return;
    }

    try {
      setState(() => _isRecording = true);

      // Mostrar di√°logo de grabaci√≥n con control manual
      final recordingSecondsNotifier = ValueNotifier<int>(0);
      bool shouldStopRecording = false;

      // Mostrar el di√°logo
      // ignore: use_build_context_synchronously
      showDialog(
        context: context,
        barrierDismissible: false,
        builder: (dialogContext) => ValueListenableBuilder<int>(
          valueListenable: recordingSecondsNotifier,
          builder: (context, seconds, child) {
            return VoiceRecordingDialog(
              recordingSeconds: seconds,
              onStop: () {
                shouldStopRecording = true;
                Navigator.of(dialogContext).pop();
              },
            );
          },
        ),
      );

      // Grabar con control manual
      final transcribedText = await voiceService.transcribeAudioOnDevice(
        onProgress: (seconds) {
          recordingSecondsNotifier.value = seconds;
        },
        waitForStopSignal: () async {
          while (!shouldStopRecording && mounted) {
            await Future.delayed(const Duration(milliseconds: 100));
          }
        },
      );

      recordingSecondsNotifier.dispose();

      // Cerrar el di√°logo si a√∫n est√° abierto
      if (mounted && Navigator.of(context).canPop()) {
        Navigator.of(context).pop();
      }

      setState(() => _isRecording = false);

      if (transcribedText.isEmpty) {
        _showError('No se detect√≥ ning√∫n comando de voz');
        return;
      }

      // Interpretar con Gemini
      final interpretation = await voiceService.interpretWithGemini(transcribedText);

      // Crear result object
      final result = VoiceCommandResult(
        success: true,
        message: 'Interpretaci√≥n completada',
        interpretation: interpretation,
        transcribedText: transcribedText,
        needsConfirmation: interpretation['user_confirmation_needed'] == true,
      );

      if (!result.success) {
        _showError(result.message ?? 'Error');
        return;
      }

      if (result.interpretation == null) {
        _showError('No se pudo interpretar el comando');
        return;
      }

      print('‚úÖ Tenemos interpretaci√≥n en FAB, extrayendo datos...');

      // Verificar si hay m√∫ltiples acciones o una sola
      final hasMultipleActions = result.interpretation!.containsKey('actions');

      if (hasMultipleActions) {
        // M√∫ltiples acciones - ir directamente a confirmaci√≥n
        print('üìä FAB - M√∫ltiples acciones detectadas');
        final actions = result.interpretation!['actions'] as List<dynamic>;
        print('üìä FAB - Total de acciones: ${actions.length}');

        for (int i = 0; i < actions.length; i++) {
          final action = actions[i] as Map<String, dynamic>;
          print('   ${i + 1}. ${action['action']} - Params: ${action['parameters']}');
        }

        // Ir directamente a confirmaci√≥n (no hay campos faltantes en workflows complejos)
        print('‚úÖ FAB - Mostrando confirmaci√≥n de m√∫ltiples acciones');

        final executionResult = await Navigator.of(context).push(
          MaterialPageRoute(
            builder: (context) => VoiceCommandConfirmationScreen(
              transcribedText: result.transcribedText!,
              interpretation: result.interpretation!,
              voiceService: voiceService,
            ),
          ),
        );

        if (executionResult != null && widget.onCommandExecuted != null) {
          widget.onCommandExecuted!(executionResult);
        }
      } else {
        // Una sola acci√≥n - verificar campos faltantes
        final action = result.interpretation!['action'] as String;
        final parameters = result.interpretation!['parameters'] as Map<String, dynamic>;
        final missingFields = RequiredFields.findMissing(action, parameters);

        print('üìä FAB - Acci√≥n: $action');
        print('üìä FAB - Par√°metros actuales: $parameters');
        print('üìä FAB - Campos faltantes: $missingFields');

        if (missingFields.isNotEmpty) {
          // Faltan campos obligatorios ‚Üí Iniciar pantalla conversacional
          print('üó£Ô∏è FAB - Faltan campos, iniciando pantalla conversacional...');

          await _startConversationalScreen(
            voiceService,
            result.transcribedText!,
            action,
            parameters,
            missingFields,
          );
        } else {
          // Todos los campos completos ‚Üí Ir a confirmaci√≥n final
          print('‚úÖ FAB - Todos los campos completos, mostrando confirmaci√≥n final');

          final executionResult = await Navigator.of(context).push(
            MaterialPageRoute(
              builder: (context) => VoiceCommandConfirmationScreen(
                transcribedText: result.transcribedText!,
                interpretation: result.interpretation!,
                voiceService: voiceService,
              ),
            ),
          );

          if (executionResult != null && widget.onCommandExecuted != null) {
            widget.onCommandExecuted!(executionResult);
          }
        }
      }

    } catch (e) {
      print('‚ùå FAB - Error: $e');
      setState(() => _isRecording = false);
      _showError(e.toString());
    }
  }

  /// Inicia la pantalla conversacional para recolectar datos faltantes
  Future<void> _startConversationalScreen(
    GeminiVoiceService voiceService,
    String originalCommand,
    String action,
    Map<String, dynamic> collectedParameters,
    List<String> missingFields,
  ) async {
    if (!mounted) return;

    print('üó£Ô∏è FAB - Iniciando pantalla conversacional');
    print('   - Comando original: "$originalCommand"');
    print('   - Acci√≥n: $action');
    print('   - Par√°metros ya recolectados: $collectedParameters');
    print('   - Campos faltantes: $missingFields');

    // Crear contexto inicial
    var conversationContext = VoiceConversationContext(
      originalCommand: originalCommand,
      action: action,
      collectedParameters: collectedParameters,
      history: [],
      missingFields: missingFields,
    );

    // Abrir la pantalla conversacional
    final completedContext = await Navigator.of(context).push<VoiceConversationContext>(
      MaterialPageRoute(
        builder: (ctx) => VoiceConversationScreen(
          context: conversationContext,
          voiceService: voiceService,
          onContextUpdated: (updatedContext) {
            conversationContext = updatedContext;
          },
        ),
      ),
    );

    // Si el usuario complet√≥ la conversaci√≥n, mostrar confirmaci√≥n final
    if (completedContext != null && mounted) {
      print('‚úÖ FAB - Conversaci√≥n completada');
      print('   - Par√°metros finales: ${completedContext.collectedParameters}');

      // Crear interpretaci√≥n completa para la pantalla de confirmaci√≥n
      final finalInterpretation = {
        'action': completedContext.action,
        'parameters': completedContext.collectedParameters,
        'confidence': 0.95,
        'user_confirmation_needed': false,
      };

      final executionResult = await Navigator.of(context).push(
        MaterialPageRoute(
          builder: (context) => VoiceCommandConfirmationScreen(
            transcribedText: completedContext.originalCommand,
            interpretation: finalInterpretation,
            voiceService: voiceService,
          ),
        ),
      );

      if (executionResult != null && widget.onCommandExecuted != null) {
        widget.onCommandExecuted!(executionResult);
      }
    } else {
      print('‚ö†Ô∏è FAB - Conversaci√≥n cancelada por el usuario');
    }
  }

  void _showError(String message) {
    if (!mounted) return;
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Text(message),
        backgroundColor: Colors.red,
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    final voiceServiceAsync = ref.watch(geminiVoiceServiceProvider);

    final isDisabled = voiceServiceAsync.when(
      data: (service) => service == null,
      loading: () => true,
      error: (_, __) => true,
    );

    return FloatingActionButton(
      onPressed: _isRecording ? null : _handleVoiceCommand,
      backgroundColor: _isRecording
          ? Colors.red
          : isDisabled
              ? Colors.grey
              : (widget.backgroundColor ?? Theme.of(context).primaryColor),
      child: _isRecording
          ? AnimatedBuilder(
              animation: _pulseController,
              builder: (context, child) {
                return Transform.scale(
                  scale: 1.0 + (_pulseController.value * 0.4),
                  child: const Icon(Icons.mic, color: Colors.white, size: 28),
                );
              },
            )
          : const Icon(Icons.mic, color: Colors.white, size: 28),
    );
  }
}

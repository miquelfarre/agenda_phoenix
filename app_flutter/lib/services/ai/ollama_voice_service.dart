import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:speech_to_text/speech_to_text.dart';
import '../../config/debug_config.dart';
import '../api_client.dart';
import '../config_service.dart';
import 'base_voice_service.dart';

/// Servicio que procesa comandos de voz usando Ollama (LLM local)
/// Compatible con la API de Ollama: https://github.com/ollama/ollama/blob/main/docs/api.md
class OllamaVoiceService implements BaseVoiceService {
  final SpeechToText _speechToText = SpeechToText();
  final String _ollamaBaseUrl;
  final String _ollamaModel;

  OllamaVoiceService({
    required String ollamaBaseUrl,
    required String ollamaModel,
  }) : _ollamaBaseUrl = ollamaBaseUrl,
       _ollamaModel = ollamaModel;

  /// Sistema prompt - debe coincidir con GeminiVoiceService
  String get _systemPrompt =>
      '''
Eres un asistente de voz para una aplicaci√≥n de agenda/calendario llamada EventyPop.
Tu trabajo es interpretar comandos de voz del usuario y convertirlos en acciones estructuradas.

ACCIONES DISPONIBLES EN LA API:

1. CREATE_EVENT - Crear un evento nuevo
   Par√°metros requeridos:
   - name: string (nombre del evento)
   - start_date: ISO 8601 (ej: "2024-03-15T14:30:00")
   Par√°metros opcionales:
   - description: string
   - calendar_id: integer (si no se especifica, se crea en el calendario principal)
   - event_type: string ("regular" o "recurring", default: "regular")

2. UPDATE_EVENT - Modificar un evento existente
   Par√°metros:
   - event_id: integer (requerido)
   - name: string (opcional)
   - start_date: ISO 8601 (opcional)
   - description: string (opcional)

3. DELETE_EVENT - Eliminar un evento
   Par√°metros:
   - event_id: integer (requerido)
   - confirmation: boolean (debe ser true)

4. LIST_EVENTS - Listar eventos
   Par√°metros opcionales:
   - calendar_id: integer
   - date_from: ISO 8601 date
   - date_to: ISO 8601 date

5. CREATE_CALENDAR - Crear un calendario nuevo
   Par√°metros:
   - name: string (requerido)
   - description: string (opcional) - Descripci√≥n detallada del calendario
   - is_discoverable: boolean (opcional) - Si es p√∫blico, ¬øpuede aparecer en b√∫squedas?

6. INVITE_TO_CALENDAR - Suscribir usuarios a un calendario (ver√°n TODOS los eventos del calendario)
   Par√°metros:
   - calendar_id: integer (requerido)
   - contact_names: array de strings (nombres de contactos, ej: ["Miquel", "Ada", "Sara"])
   - role: string (opcional: "owner", "editor", "member", default: "member")
   - message: string (opcional)

7. INVITE_USER - Invitar usuario a un evento espec√≠fico (solo ver√° ESE evento)
   Par√°metros:
   - event_id: integer (requerido)
   - user_id: integer o email: string (requerido)
   - message: string (opcional) - Nota o mensaje personal para el invitado

8. ADD_EVENT_NOTE - A√±adir/actualizar nota personal al evento (para el creador/owner)
   Par√°metros:
   - event_id: integer (requerido)
   - note: string (requerido) - Nota personal para recordar algo sobre el evento
   Nota: Si el owner ya tiene una nota en este evento, se actualizar√° con la nueva

FORMATO DE RESPUESTA:
Debes responder √öNICAMENTE con un objeto JSON v√°lido, sin texto adicional, sin markdown.

IMPORTANTE: Si el usuario pide M√öLTIPLES ACCIONES en un solo comando (ej: "crea un calendario Y crea un evento Y invita a usuarios"),
debes devolver un array "actions" con todas las acciones en secuencia.

Estructura del JSON para UNA acci√≥n:
{
  "action": "NOMBRE_ACCION",
  "parameters": {
    // par√°metros espec√≠ficos de la acci√≥n
  },
  "confidence": 0.0-1.0,
  "user_confirmation_needed": boolean,
  "clarification_message": "mensaje opcional si necesitas m√°s info del usuario",
  "suggestions": [
    "¬øQuieres a√±adir una descripci√≥n al evento?",
    "¬øPrefieres que el calendario sea p√∫blico?"
  ]
}

Estructura del JSON para M√öLTIPLES acciones:
{
  "actions": [
    {
      "action": "PRIMERA_ACCION",
      "parameters": { ... },
      "depends_on_previous": false
    },
    {
      "action": "SEGUNDA_ACCION",
      "parameters": {
        // Usa "{{previous_result.id}}" para referenciar el resultado de la acci√≥n anterior
        "calendar_id": "{{previous_result.id}}"
      },
      "depends_on_previous": true
    }
  ],
  "confidence": 0.0-1.0,
  "user_confirmation_needed": boolean,
  "suggestions": [
    "¬øQuieres a√±adir una descripci√≥n a alguno de los eventos?",
    "¬øEl calendario debe ser p√∫blico o privado?",
    "¬øQuieres configurar recordatorios para estos eventos?"
  ]
}

REGLAS:
- Si el usuario usa conectores como "Y", "luego", "despu√©s", "tambi√©n", identifica M√öLTIPLES ACCIONES
- Usa el formato "actions" array cuando hay m√°s de una acci√≥n
- Marca "depends_on_previous": true si una acci√≥n necesita el resultado de la anterior
- Para fechas relativas ("ma√±ana", "el viernes", "la pr√≥xima semana"), calcula la fecha exacta
- La fecha de hoy es: ${DateTime.now().toIso8601String().split('T')[0]}
- Si no entiendes el comando, usa action: "UNKNOWN"
- Mant√©n confidence alto (>0.8) solo si est√°s seguro
- IMPORTANTE: Si hay m√∫ltiples contactos para invitar (ej: "Miquel, Ada y Sara"), crea UNA ACCI√ìN POR CADA CONTACTO con contact_names: ["nombre"]
- IMPORTANTE: Incluye un campo "suggestions" con preguntas √∫tiles para que el usuario mejore/ajuste las acciones antes de ejecutarlas

IMPORTANTE - Diferencia entre INVITE_TO_CALENDAR e INVITE_USER:
- "Invita a X al calendario" / "Suscribe a X al calendario" / "Comparte el calendario con X" ‚Üí INVITE_TO_CALENDAR
- "Invita a X al evento" / "A√±ade a X al evento" ‚Üí INVITE_USER
- Si el usuario dice "invita a X" sin especificar, y hay un calendario reci√©n creado ‚Üí INVITE_TO_CALENDAR
''';

  @override
  Future<Map<String, dynamic>> interpretWithAI(
    String transcribedText, {
    String? customPrompt,
  }) async {
    try {
      DebugConfig.info(
        'Enviando a Ollama: $transcribedText',
        tag: 'VoiceService',
      );

      final fullPrompt =
          customPrompt ??
          '$_systemPrompt\n\nComando del usuario: "$transcribedText"';

      final response = await http
          .post(
            Uri.parse('$_ollamaBaseUrl/api/generate'),
            headers: {'Content-Type': 'application/json'},
            body: jsonEncode({
              'model': _ollamaModel,
              'prompt': fullPrompt,
              'stream': false,
              'format': 'json',
            }),
          )
          .timeout(
            const Duration(
              minutes: 5,
            ), // Timeout de 5 minutos para modelos pesados
            onTimeout: () {
              throw Exception(
                'Timeout: Ollama model took more than 5 minutes to respond. '
                'Consider using a lighter model.',
              );
            },
          );

      if (response.statusCode != 200) {
        DebugConfig.error(
          'Error Ollama API: ${response.statusCode} - ${response.body}',
          tag: 'VoiceService',
        );
        throw Exception('Error calling Ollama API: ${response.statusCode}');
      }

      // Parse Ollama response
      final jsonResponse = jsonDecode(response.body);
      final textResponse = jsonResponse['response'] as String?;

      if (textResponse == null || textResponse.isEmpty) {
        throw Exception('No response received from Ollama');
      }

      DebugConfig.info(
        'Respuesta de Ollama: $textResponse',
        tag: 'VoiceService',
      );

      // Limpiar la respuesta (eliminar markdown si lo hay)
      String cleanedResponse = textResponse.trim();
      if (cleanedResponse.startsWith('```json')) {
        cleanedResponse = cleanedResponse.substring(7);
      }
      if (cleanedResponse.startsWith('```')) {
        cleanedResponse = cleanedResponse.substring(3);
      }
      if (cleanedResponse.endsWith('```')) {
        cleanedResponse = cleanedResponse.substring(
          0,
          cleanedResponse.length - 3,
        );
      }
      cleanedResponse = cleanedResponse.trim();

      // Parsear la respuesta JSON del LLM
      final interpretation =
          jsonDecode(cleanedResponse) as Map<String, dynamic>;

      return interpretation;
    } catch (e, _) {
      DebugConfig.error(
        'Error al interpretar con Ollama: $e',
        tag: 'VoiceService',
      );
      rethrow;
    }
  }

  @override
  Future<dynamic> executeAction(Map<String, dynamic> interpretation) async {
    try {
      final action = interpretation['action'] as String;
      final parameters = interpretation['parameters'] as Map<String, dynamic>;
      final apiClient = ApiClient();

      DebugConfig.info(
        'Ejecutando acci√≥n: $action con par√°metros: $parameters',
        tag: 'VoiceService',
      );

      switch (action) {
        case 'CREATE_EVENT':
          final result = await apiClient.createEvent(parameters);
          return result;

        case 'UPDATE_EVENT':
          final eventId = parameters['event_id'] as int;
          parameters.remove('event_id');
          final result = await apiClient.updateEvent(eventId, parameters);
          return result;

        case 'DELETE_EVENT':
          final eventId = parameters['event_id'] as int;
          await apiClient.deleteEvent(eventId);
          return {'success': true, 'message': 'Evento eliminado'};

        case 'CREATE_CALENDAR':
          final result = await apiClient.createCalendar(parameters);
          return result;

        case 'INVITE_USER':
          final eventId = parameters['event_id'] as int;
          final userId = parameters['user_id'] as int?;
          final message = parameters['message'] as String?;
          final interactionData = {
            'event_id': eventId,
            'user_id': userId,
            'interaction_type': 'invited',
            'status': 'pending',
          };
          // A√±adir nota/mensaje si existe
          if (message != null && message.isNotEmpty) {
            interactionData['note'] = message;
          }
          final result = await apiClient.createInteraction(interactionData);
          return result;

        case 'ADD_EVENT_NOTE':
          final eventId = parameters['event_id'] as int;
          final note = parameters['note'] as String;

          // Obtener el ID del usuario actual (owner) desde ConfigService
          final currentUserId = ConfigService.instance.currentUserId;

          // Verificar si ya existe una interacci√≥n del owner para este evento
          final existingInteractions = await apiClient.fetchInteractions(
            eventId: eventId,
            userId: currentUserId,
          );

          if (existingInteractions.isNotEmpty) {
            // Ya existe una interacci√≥n - actualizar la nota
            final existingInteraction = existingInteractions.first;
            final interactionId = existingInteraction['id'] as int;
            final result = await apiClient.patchInteraction(interactionId, {
              'note': note,
            });
            return result;
          } else {
            // No existe - crear nueva interacci√≥n tipo 'joined' para el owner con la nota
            final interactionData = {
              'event_id': eventId,
              'user_id': currentUserId,
              'interaction_type': 'joined',
              'status': 'accepted',
              'note': note,
              'invited_by_user_id':
                  currentUserId, // El owner se a√±ade a s√≠ mismo
            };
            final result = await apiClient.createInteraction(interactionData);
            return result;
          }

        case 'UNKNOWN':
          return {
            'success': false,
            'message':
                interpretation['clarification_message'] ??
                'No entend√≠ el comando. Por favor, intenta de nuevo.',
          };

        default:
          throw Exception('Unrecognized action: $action');
      }
    } catch (e) {
      DebugConfig.error('Error al ejecutar acci√≥n: $e', tag: 'VoiceService');
      rethrow;
    }
  }

  @override
  Future<String> transcribeAudioOnDevice({
    Function(int secondsElapsed)? onProgress,
    Future<void> Function()? waitForStopSignal,
  }) async {
    DebugConfig.info('üé§ Inicializando speech-to-text...', tag: 'VoiceService');

    try {
      // Inicializar speech-to-text si no est√° ya inicializado
      if (!_speechToText.isAvailable) {
        final available = await _speechToText.initialize(
          onError: (error) {
            DebugConfig.error(
              'Error en speech-to-text: ${error.errorMsg}',
              tag: 'VoiceService',
            );
          },
          onStatus: (status) {},
        );

        if (!available) {
          throw Exception(
            'Speech-to-text not available on this device',
          );
        }
      }

      DebugConfig.info('Speech-to-text inicializado', tag: 'VoiceService');

      String transcribedText = '';
      bool shouldStop = false;
      int secondsElapsed = 0;
      const maxSeconds = 30;

      // Callback para capturar texto en tiempo real
      await _speechToText.listen(
        onResult: (result) {
          transcribedText = result.recognizedWords;
        },
        localeId: 'es_ES',
        listenFor: const Duration(seconds: 30), // M√°ximo 30 segundos
        pauseFor: const Duration(seconds: 30), // No parar por silencio
      );

      // Timer para actualizar el progreso
      final progressTimer = Future(() async {
        while (!shouldStop && secondsElapsed < maxSeconds) {
          await Future.delayed(const Duration(seconds: 1));
          secondsElapsed++;
          onProgress?.call(secondsElapsed);
        }
      });

      // Esperar se√±al del usuario o timeout
      if (waitForStopSignal != null) {
        await Future.any([
          waitForStopSignal.call().then((_) {
            shouldStop = true;
          }),
          progressTimer,
        ]);
      } else {
        await progressTimer;
      }

      // Stop listening
      await _speechToText.stop();

      DebugConfig.info(
        'Texto transcrito: $transcribedText',
        tag: 'VoiceService',
      );

      if (transcribedText.isEmpty) {
        throw Exception('Could not transcribe audio');
      }

      return transcribedText;
    } catch (e) {
      DebugConfig.error('Error en transcripci√≥n: $e', tag: 'VoiceService');
      rethrow;
    }
  }

  @override
  Future<VoiceCommandResult> processVoiceCommand() async {
    DebugConfig.info(
      'üöÄ ===== INICIANDO processVoiceCommand() =====',
      tag: 'VoiceService',
    );
    try {
      // 1. Transcribir audio (on-device)
      final transcribedText = await transcribeAudioOnDevice();

      // 2. Interpretar con Ollama
      final interpretation = await interpretWithAI(transcribedText);

      // Return result
      return VoiceCommandResult(
        success: true,
        transcribedText: transcribedText,
        interpretation: interpretation,
        needsConfirmation: interpretation['user_confirmation_needed'] ?? true,
      );
    } catch (e) {
      DebugConfig.error(
        'Error al procesar comando de voz: $e',
        tag: 'VoiceService',
      );
      return VoiceCommandResult(success: false, message: 'Error processing voice command: $e');
    }
  }
}
